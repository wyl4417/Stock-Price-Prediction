{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59693612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56687ee1",
   "metadata": {},
   "source": [
    "The next step is to split the data into training and test sets to avoid overfitting and to be able to investigate the generalization ability of our model. To learn more about overfitting read this article:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200ac587",
   "metadata": {},
   "source": [
    "The target value to be predicted is going to be the “Close” stock price value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e37162",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = df.iloc[:800, 1:2].values\n",
    "test_set = df.iloc[800:, 1:2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abbedc7",
   "metadata": {},
   "source": [
    "It’s a good idea to normalize the data before model fitting. This will boost the performance. You can read more here for the Min-Max Scaler:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592606ff",
   "metadata": {},
   "source": [
    "Let’s build the input features with time lag of 1 day (lag 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d8372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "# Creating a data structure with 60 time-steps and 1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, 800):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "#(740, 60, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a01b21",
   "metadata": {},
   "source": [
    "We have now reshaped the data into the following format (#values, #time-steps, #1 dimensional output).\n",
    "Now, it’s time to build the model. We will build the LSTM with 50 neurons and 4 hidden layers. Finally, we will assign 1 neuron in the output layer for predicting the normalized stock price. We will use the MSE loss function and the Adam stochastic gradient descent optimizer.\n",
    "Note: the following will take some time (~5min)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feeb73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#Adding the first LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "model.add(LSTM(units = 50))\n",
    "model.add(Dropout(0.2))\n",
    "# Adding the output layer\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "model.fit(X_train, y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a01a6",
   "metadata": {},
   "source": [
    "When the fitting is finished you should see something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0414c4a",
   "metadata": {},
   "source": [
    "Prepare the test data (reshape them):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f6595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted stock price of 2017\n",
    "dataset_train = df.iloc[:800, 1:2]\n",
    "dataset_test = df.iloc[800:, 1:2]\n",
    "dataset_total = pd.concat((dataset_train, dataset_test), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(60, 519):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "print(X_test.shape)\n",
    "# (459, 60, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b629f6cd",
   "metadata": {},
   "source": [
    "Make Predictions using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f89c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = model.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1c9364",
   "metadata": {},
   "source": [
    "Let’s visualize the results now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f8e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the results\n",
    "plt.plot(df.loc[800:, ‘Date’],dataset_test.values, color = ‘red’, label = ‘Real TESLA Stock Price’)\n",
    "plt.plot(df.loc[800:, ‘Date’],predicted_stock_price, color = ‘blue’, label = ‘Predicted TESLA Stock Price’)\n",
    "plt.xticks(np.arange(0,459,50))\n",
    "plt.title('TESLA Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('TESLA Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adbbf30",
   "metadata": {},
   "source": [
    "5. Results\n",
    "Using a lag of 1 (i.e. step of one day):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7917c6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
